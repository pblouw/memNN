{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "import collections\n",
    "\n",
    "from nengo import spa\n",
    "from nengo.spa import pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/en/qa1_single-supporting-fact_test.txt','r') as f:\n",
    "    text = f.read()  \n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tokens = [x.lower() for x in set(tokens)]\n",
    "tokens = [x for x in tokens if x not in string.punctuation]\n",
    "tokens = [x for x in tokens if not x.isdigit()]\n",
    "\n",
    "pos_tags = nltk.data.load('help/tagsets/upenn_tagset.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TextVocabulary(spa.Vocabulary):\n",
    "    def __getitem__(self, key):\n",
    "        value = self.pointers.get(key, None)\n",
    "        if value is None:\n",
    "            value = self.create_pointer()\n",
    "            self.add(key, value)\n",
    "        return value\n",
    "\n",
    "    def add(self, key, p):\n",
    "        if not isinstance(p, pointer.SemanticPointer):\n",
    "            p = pointer.SemanticPointer(p)\n",
    "\n",
    "        if key in self.pointers:\n",
    "            raise KeyError(\"The semantic pointer '%s' already exists\" % key)\n",
    "\n",
    "        self.pointers[key] = p\n",
    "        self.keys.append(key)\n",
    "        self.vectors = np.vstack([self.vectors, p.v])\n",
    "\n",
    "        # Generate vector pairs\n",
    "        if self.include_pairs and len(self.keys) > 1:\n",
    "            for k in self.keys[:-1]:\n",
    "                self.key_pairs.append('%s*%s' % (k, key))\n",
    "                v = (self.pointers[k] * p).v\n",
    "                self.vector_pairs = np.vstack([self.vector_pairs, v])\n",
    "\n",
    "D = 512\n",
    "    \n",
    "wrd_voc = TextVocabulary(D)\n",
    "pos_voc = TextVocabulary(D)\n",
    "\n",
    "for token in tokens:\n",
    "    wrd_voc[token]\n",
    "    \n",
    "for pos in pos_tags:\n",
    "    pos_voc[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRP$', 'VBG', 'VBD', '``', 'VBN', ',', \"''\", 'VBP', 'WDT', 'JJ', 'WP', 'VBZ', 'DT', 'RP', '$', 'NN', ')', '(', 'FW', 'POS', '.', 'TO', 'LS', 'RB', ':', 'NNS', 'NNP', 'VB', 'WRB', 'CC', 'PDT', 'RBS', 'RBR', 'CD', 'PRP', 'EX', 'IN', 'WP$', 'MD', 'NNPS', '--', 'JJS', 'JJR', 'SYM', 'UH']\n",
      "\n",
      "['office', 'is', 'moved', 'back', 'daniel', 'bedroom', 'john', 'mary', 'bathroom', 'to', 'travelled', 'hallway', 'garden', 'sandra', 'where', 'the', 'kitchen', 'journeyed', 'went']\n"
     ]
    }
   ],
   "source": [
    "print pos_voc.keys\n",
    "print ''\n",
    "print wrd_voc.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "Fact = namedtuple('Fact', ['sentence'])\n",
    "Query = namedtuple('Query', ['sentence', 'answer', 'support'])\n",
    "\n",
    "\n",
    "def load(filename):\n",
    "    stories = [[]]\n",
    "\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            idx, parsed = parse_line(line)\n",
    "            if idx < len(stories[-1]):\n",
    "                stories.append([])\n",
    "            stories[-1].append(parsed)\n",
    "\n",
    "    return stories\n",
    "\n",
    "\n",
    "def parse_line(line):\n",
    "    idx, sentence = line.split(' ', 1)\n",
    "    idx = int(idx)\n",
    "    if '?' in sentence:\n",
    "        parsed = parse_query(sentence)\n",
    "    else:\n",
    "        parsed = parse_fact(sentence)\n",
    "    return idx, parsed\n",
    "\n",
    "\n",
    "def parse_fact(fact):\n",
    "    return Fact(fact.strip())\n",
    "\n",
    "def parse_query(sentence):\n",
    "    query, answer, support = sentence.split('\\t')\n",
    "    return Query(query.strip(), answer.strip(), int(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John', 'NNP'), ('travelled', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('hallway.', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "stories = load('data/en/qa1_single-supporting-fact_test.txt')\n",
    "story = stories[0]\n",
    "\n",
    "for item in story:\n",
    "    if isinstance(item, Fact):\n",
    "        tagged = nltk.pos_tag(item.sentence.split())\n",
    "        print tagged\n",
    "        sen_sum = pointer.SemanticPointer(np.zeros(D))\n",
    "        for pair in tagged:\n",
    "            wrd = pair[0]\n",
    "            pos = pair[1]\n",
    "            sen_sum += wrd_voc[wrd] * pos_voc[pos]\n",
    "        break\n",
    "\n",
    "unbind = sen_sum * ~wrd_voc['travelled']\n",
    "unbind.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41VBD;0.08.;0.08);0.06PRP\n"
     ]
    }
   ],
   "source": [
    "print pos_voc.text(unbind, minimum_count=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
